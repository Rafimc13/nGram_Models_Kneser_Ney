{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3XAzE9sPsa1"
   },
   "source": [
    "# Part 01 - Exercise 3 (n-gram language models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUZQrmeEPz0N"
   },
   "source": [
    "## Organizing our Data\n",
    "\n",
    "At first, we downloaded via *nltk* package a valuable corpus such as 'reuters'. Moreover, we downloaded the method tokenization 'punkt' via nltk package.\n",
    "We splitted our data into training, development and test set and we transformed any rare word (freq<=10) or out-of-vocabulary word to the special token 'UNK'.\n",
    "As we can see from the printed console, a lot of words transformed into the special token 'UNK' in order to be able to handle the unknown words better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jbiEuUgPPmMK",
    "outputId": "823804c1-4d88-4693-80e0-35ba41d45c8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total size of our vocabulary is: 12038\n",
      "Example sentence of our training set:\n",
      "It|has|appeared|to|traders|for|some|years|that|the|EC|'|s|export|policy|is|<UNK>|responsive|to|changing|patterns|of|demand|,|it|says|.\n",
      "Example sentence of our development set:\n",
      "RIO|DE|<UNK>|<UNK>|STRIKE|Rio|de|Janeiro|'|s|3|,|500|<UNK>|went|on|strike|for|an|indefinite|period|today|to|demand|wage|increases|,|a|spokesman|for|the|<UNK>|said|.\n",
      "Example sentence of our test set:\n",
      "The|foreign|currency|purchased|was|used|by|the|Treasury|to|repay|foreign|debt|and|did|not|affect|the|Bank|'|s|foreign|exchange|reserves|.\n"
     ]
    }
   ],
   "source": [
    "# If you running for first time uncomment the following 3 lines iot download the corpus\n",
    "# import nltk\n",
    "# nltk.download('reuters')\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import reuters\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "import math\n",
    "from more_itertools import windowed\n",
    "\n",
    "\n",
    "# Load the 'reuters' corpus\n",
    "sentences = reuters.sents()\n",
    "# Splitting data into Training, Development and Test set\n",
    "train_sents, test_sents = train_test_split(reuters.sents(), test_size=0.1, random_state=42)\n",
    "dev_sents, test_sents = train_test_split(test_sents, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "# Transform the train sentences into words\n",
    "train_words = [word for sentence in train_sents for word in sentence]\n",
    "freq_dist_train = FreqDist(train_words)\n",
    "\n",
    "# Replace rare words in train set\n",
    "cleaned_train_sentences = []\n",
    "for sentence in train_sents:\n",
    "    cleaned_train_sentence = [word if freq_dist_train[word] > 5 else '<UNK>' for word in sentence]\n",
    "    cleaned_train_sentences.append(cleaned_train_sentence)\n",
    "\n",
    "# Build our vocab based on training set\n",
    "vocab = set([word for sentence in cleaned_train_sentences for word in sentence])\n",
    "\n",
    "print(f'The total size of our vocabulary is: {len(vocab)}')\n",
    "\n",
    "\n",
    "print('Example sentence of our training set:')\n",
    "print('|'.join(cleaned_train_sentences[0]))\n",
    "\n",
    "# Transform the development sentences into words\n",
    "dev_words = [word for sentence in dev_sents for word in sentence]\n",
    "freq_dist_dev = FreqDist(dev_words)\n",
    "\n",
    "# Replace rare words or Out-of-Vocabulary words in dev set\n",
    "cleaned_dev_sentences = []\n",
    "for sentence in dev_sents:\n",
    "    cleaned_dev_sentence = [word if word in vocab else '<UNK>' for word in sentence]\n",
    "    cleaned_dev_sentences.append(cleaned_dev_sentence)\n",
    "\n",
    "print('Example sentence of our development set:')\n",
    "print('|'.join(cleaned_dev_sentences[0]))\n",
    "\n",
    "# Transform the test sentences into words\n",
    "test_words = [word for sentence in test_sents for word in sentence]\n",
    "freq_dist_test = FreqDist(test_words)\n",
    "\n",
    "# Replace rare words or Out-of-Vocabulary words in test set\n",
    "cleaned_test_sentences = []\n",
    "for sentence in test_sents:\n",
    "    cleaned_test_sentence = [word if word in vocab else '<UNK>' for word in sentence]\n",
    "    cleaned_test_sentences.append(cleaned_test_sentence)\n",
    "\n",
    "print('Example sentence of our test set:')\n",
    "print('|'.join(cleaned_test_sentences[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrDchol4PXMZ"
   },
   "source": [
    "## i) Build our unigram, bigram & trigram model\n",
    "\n",
    "In the following block of code we used Counter() in order to cosntruct our ngram models (unigram, bigram, trigram) and simultaneously to count the frequency of each word. In the printed console we can observe the most common words for each ngram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49pHN-H9Qhn3",
    "outputId": "2047f51e-ae45-40e8-eebc-79abc50ff32b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most common words for unigram counter:\n",
      "[(('.',), 84992),\n",
      " ((',',), 64910),\n",
      " (('the',), 52391),\n",
      " (('<UNK>',), 52158),\n",
      " (('of',), 32300),\n",
      " (('to',), 30666),\n",
      " (('in',), 23750),\n",
      " (('said',), 22668),\n",
      " (('and',), 22618),\n",
      " (('a',), 21061)]\n",
      "10 most common words for bigram counter:\n",
      "[(('.', '<e>'), 43915),\n",
      " ((',', '000'), 9173),\n",
      " ((\"'\", 's'), 8336),\n",
      " (('<s>', 'The'), 7992),\n",
      " (('lt', ';'), 7845),\n",
      " (('&', 'lt'), 7842),\n",
      " (('said', '.'), 7119),\n",
      " (('<s>', '<UNK>'), 6563),\n",
      " (('of', 'the'), 6131),\n",
      " (('in', 'the'), 5792)]\n",
      "10 most common words for trigram counter:\n",
      "[(('.', '<e>', '<e>'), 43915),\n",
      " (('<s>', '<s>', 'The'), 7992),\n",
      " (('&', 'lt', ';'), 7841),\n",
      " (('said', '.', '<e>'), 7118),\n",
      " (('<s>', '<s>', '<UNK>'), 6563),\n",
      " (('lt', ';', '<UNK>'), 5153),\n",
      " (('U', '.', 'S'), 5100),\n",
      " (('.', 'S', '.'), 4780),\n",
      " ((';', '<UNK>', '>'), 3299),\n",
      " (('<s>', '<s>', '\"'), 3237)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Build unigram, bigram and trigram counters for our training set\n",
    "unigram_counter = Counter()\n",
    "bigram_counter = Counter()\n",
    "trigram_counter = Counter()\n",
    "\n",
    "for sent in cleaned_train_sentences:\n",
    "\n",
    "    unigram_counter.update([gram for gram in ngrams(sent, 1, pad_left=True, pad_right=True,\n",
    "                                                    left_pad_symbol='<s>', right_pad_symbol='<e>')])\n",
    "    bigram_counter.update([gram for gram in ngrams(sent, 2, pad_left=True, pad_right=True,\n",
    "                                                       left_pad_symbol='<s>', right_pad_symbol='<e>')])\n",
    "    trigram_counter.update([gram for gram in ngrams(sent, 3, pad_left=True, pad_right=True,\n",
    "                                                        left_pad_symbol='<s>', right_pad_symbol='<e>')])\n",
    "\n",
    "print('10 most common words for unigram counter:')\n",
    "pprint(unigram_counter.most_common(10))\n",
    "print('10 most common words for bigram counter:')\n",
    "pprint(bigram_counter.most_common(10))\n",
    "print('10 most common words for trigram counter:')\n",
    "pprint(trigram_counter.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cnwi9mDL-M-W",
    "outputId": "4c78dcaa-8556-4b4e-f0b4-4afcfb5dddc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1sentence3\n",
      "sentence2sentence4\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGxdlRzeQqAa"
   },
   "source": [
    "## Calculation of bigram and trigram probabilities via Laplace smoothing\n",
    "\n",
    "In the following block of code we constructed a function which is responsible for calculating the probability of a ngram (bigram or trigram) model.\n",
    "We used Laplace smoothing for this purpose. We also added the special tokens in order to include them in the size of the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWk04lIfQrHk",
    "outputId": "b3acfb60-9158-4603-91d0-ac945c31f9ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total size of our vocabulary size based on the training set and special tokens is: 12040\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter alpha. Fine-tuning on the development set\n",
    "alpha = 0.1\n",
    "\n",
    "# Sum the tokens for the whole corpus (training, dev & test sets)\n",
    "tokens = [token for sent in sentences for token in sent]\n",
    "# Calculate vocabulary size (including any special tokens)\n",
    "special_tokens = ['<s>', '<e>']\n",
    "vocab_size = len(vocab) + len(special_tokens)\n",
    "print(f'The total size of our vocabulary size based on the training set and special tokens is: {vocab_size}')\n",
    "\n",
    "\n",
    "def calc_ngram_proba(ngram_counter, ngram_minus_one_counter, ngram, alpha, vocab_size):\n",
    "    \"\"\"\n",
    "    Calculate ngram probability with Laplace smoothing\n",
    "    :param bigram_counter: Counter which the key is a tuple of ngram and value its frequency\n",
    "    :param gram_counter: Counter which the key is a tuple of n-1gram and value its frequency\n",
    "    :param ngram: tuple\n",
    "    :param alpha: float hyperparameter for Laplace smoothing\n",
    "    :param vocab_size: int value which defines the whole size of the corpus\n",
    "    :return: float probability of the ngram inside the corpus\n",
    "    \"\"\"\n",
    "    ngram_count = ngram_counter[ngram]\n",
    "    context = ngram[:-1]\n",
    "    if context == ('<s>', '<s>',) or context == ('<s>',):\n",
    "        ngram_minus_one_count = len(cleaned_train_sentences)\n",
    "    else:\n",
    "        ngram_minus_one_count = ngram_minus_one_counter[context]\n",
    "    if ngram_count>ngram_minus_one_count:\n",
    "        print(f'The following ngram occurs an error in the counter: {ngram}')\n",
    "    ngram_prob = (ngram_count + alpha) / (ngram_minus_one_count + (alpha * vocab_size))\n",
    "    return math.log2(ngram_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lH2MdYxGQviA"
   },
   "source": [
    "## ii) Calculation of probabilities, Cross-Entropy and Perplexity for our bigram model (Laplace smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KA7XfuQ3Qx5X",
    "outputId": "4023f0da-8bb7-4788-bd28-698bb96a4289"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total Cross-Entropy of bigram model for our Test set is: 7.155\n",
      "Perplexity of bigram model for Test Set: 142.546\n"
     ]
    }
   ],
   "source": [
    "# Calculate bigram probability and Cross-Entropy of sentences in the test set\n",
    "total_log_proba_bigram = 0.0\n",
    "for sent in cleaned_test_sentences:\n",
    "    # Pad the sentence with '<s>' and '<e>' tokens\n",
    "    padded_sent = ['<s>'] + sent + ['<e>']\n",
    "\n",
    "    # Iterate over the bigrams of the sentence\n",
    "    for first_token, second_token in windowed(padded_sent, 2):\n",
    "        # if first_token == '<s>': # Avoid calculating that because unigram counter does not have counts for <s>\n",
    "        #     pass\n",
    "        # else:\n",
    "        bigram = (first_token, second_token)\n",
    "        bigram_prob = calc_ngram_proba(bigram_counter, unigram_counter, bigram, alpha, vocab_size)\n",
    "        total_log_proba_bigram += bigram_prob\n",
    "\n",
    "# Calculation of total tokens for test set, including only 'end' token for each sentence\n",
    "num_tokens = sum(len(sent) + 2 for sent in cleaned_test_sentences)\n",
    "\n",
    "cross_entropy_bigram = - total_log_proba_bigram / num_tokens\n",
    "print(f\"The total Cross-Entropy of bigram model for our Test set is: {cross_entropy_bigram:.3f}\")\n",
    "\n",
    "# Calculation of the perplexity of bigram model for the test set\n",
    "\n",
    "bigram_perplexity = 2 ** (cross_entropy_bigram)\n",
    "print(f\"Perplexity of bigram model for Test Set: {bigram_perplexity:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlYUmZQ5Q32d"
   },
   "source": [
    "## Calculation of probabilities, Cross-Entropy and Perplexity for our trigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0jJn28-wQ046",
    "outputId": "fa396eff-c336-49eb-aa5d-ea8b9ee404a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total Cross-Entropy of trigram model for our Test set is:  8.801\n",
      "Perplexity of trigram model for Test Set: 445.916\n"
     ]
    }
   ],
   "source": [
    "# Calculate trigram probability and Cross-Entropy of sentences in the test set\n",
    "total_log_proba_trigram = 0.0\n",
    "for sent in cleaned_test_sentences:\n",
    "    # Pad the sentence with '<s>' and '<e>' tokens\n",
    "    padded_sent = ['<s>'] + ['<s>'] + sent + ['<e>']\n",
    "\n",
    "    # Iterate over the bigrams of the sentence\n",
    "    for first_token, second_token, third_token in windowed(padded_sent, 3):\n",
    "        if first_token == '<s>' and second_token == '<s>': # Avoid calculating that because bigram counter does not have counts for <s>, <s>\n",
    "            pass\n",
    "        else:\n",
    "            trigram = (first_token, second_token, third_token)\n",
    "            trigram_prob = calc_ngram_proba(trigram_counter, bigram_counter, trigram, alpha, vocab_size)\n",
    "            total_log_proba_trigram += trigram_prob\n",
    "\n",
    "cross_entropy_trigram = - total_log_proba_trigram / num_tokens\n",
    "print(f\"The total Cross-Entropy of trigram model for our Test set is: {cross_entropy_trigram: .3f}\")\n",
    "\n",
    "# Calculation of the perplexity of bigram model for the test set\n",
    "trigram_perplexity = 2 ** (cross_entropy_trigram)\n",
    "print(f\"Perplexity of trigram model for Test Set: {trigram_perplexity:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Nu3lDkSQ8SN"
   },
   "source": [
    "## Calculation of bigram and trigram probabilities via Improved Kneser-Ney smoothing\n",
    "\n",
    "In the following block of code we constructed a function which is responsible for calculating the probability of a ngram (bigram or trigram) model.\n",
    "In the following block of code we used Kneser-Ney smoothing which is more challenging and efficient. We generalized the purpose of our function in order to calculate either for bigram or trigram models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "78QiZKwaQ-1U"
   },
   "outputs": [],
   "source": [
    "def calc_kneser_ney_proba(ngram_counter, ngram_minus_one_counter, continuation_counts, ngram, delta, prefixes_counter):\n",
    "    \"\"\"\n",
    "    Calculate ngram probability with simplified Kneser-Ney smoothing for bigrams or trigrams\n",
    "    :param ngram_counter: Counter for ngrams (bigrams or trigrams)\n",
    "    :param ngram_minus_one_counter: Counter for n-1 grams\n",
    "    :param continuation_counts: Counter for continuation counts\n",
    "    :param total_continuations: Total number of unique continuations\n",
    "    :param ngram: tuple representing the ngram (bigram or trigram)\n",
    "    :param delta: discount value\n",
    "    :param prefixes_counter: Counter for prefixes of ngram\n",
    "    :return: float probability of the ngram\n",
    "    \"\"\"\n",
    "    # print(ngram)\n",
    "    ngram_count = ngram_counter[ngram]\n",
    "    context = ngram[:-1]\n",
    "    if context == ('<s>', '<s>',) or context == ('<s>',):\n",
    "        ngram_minus_one_count = len(cleaned_train_sentences)\n",
    "    else:\n",
    "        ngram_minus_one_count = ngram_minus_one_counter[context]\n",
    "\n",
    "    adjusted_count = max(ngram_count - delta, 0)\n",
    "    epsilon = 1e-10\n",
    "\n",
    "    # For bigrams, use the second token for continuation, for trigrams use the third token\n",
    "    continuation_token = ngram[-1]\n",
    "\n",
    "    # Calculate our interpolation weight\n",
    "    continuation_prob = continuation_counts[continuation_token] / len(ngram_counter)\n",
    "    if continuation_prob>=1 or continuation_prob==0:\n",
    "        print(f'The continuation probability is: {continuation_prob:.3f}')\n",
    "    alpha_weight = (delta * prefixes_counter[(context)] + epsilon) / (ngram_minus_one_count + epsilon)\n",
    "    kn_probability = adjusted_count / (ngram_minus_one_count + epsilon) + alpha_weight * continuation_prob\n",
    "    if kn_probability==0 or kn_probability>=1:\n",
    "        print(f'Error occured with ngram: {ngram}. Probability more than 1 or 0.')\n",
    "    return kn_probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JR5f3eN2RBOL"
   },
   "source": [
    "## Use of Kneser-Ney smoothing technique and Calculation of probabilities, Cross-Entropy and Perplexity - Refined Version\n",
    "\n",
    "We implemented Kneser-Ney smoothing ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQwXMZu1RD0U",
    "outputId": "77ddad03-a594-4139-816c-c36ee8b5eebd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 89223/256000 [00:00<00:00, 373374.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total Cross-Entropy of bigram model via Kneser-Ney smoothing for our Test set is:  6.185\n",
      "Perplexity of bigram model for Test Set: 72.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Calculate continuation counts\n",
    "continuation_counts_bi = Counter([bigram[1] for bigram in bigram_counter])\n",
    "\n",
    "\n",
    "# Convert list of n-grams to a list of tuples\n",
    "ngram_tuples_bi = [tuple(ng) for ng in bigram_counter]\n",
    "\n",
    "# Create a Counter for the prefixes\n",
    "prefixes_counter_bi = Counter(ng[:-1] for ng in ngram_tuples_bi)\n",
    "\n",
    "total_log_proba_bigram_kn = 0.0\n",
    "delta = 0.5\n",
    "with tqdm(total=256000) as pbar:  # Check our time and iters remaining!\n",
    "    for sent in cleaned_test_sentences:\n",
    "        padded_sent = ['<s>'] + sent + ['<e>']\n",
    "\n",
    "        for first_token, second_token in windowed(padded_sent, 2):\n",
    "            bigram = (first_token, second_token)\n",
    "            bigram_prob = calc_kneser_ney_proba(bigram_counter, unigram_counter, continuation_counts_bi,\n",
    "                                                    bigram, delta, prefixes_counter_bi)\n",
    "            total_log_proba_bigram_kn += math.log2(bigram_prob)\n",
    "            pbar.update(1)  # Update the progress bar\n",
    "\n",
    "cross_entropy_bigram_kn = - total_log_proba_bigram_kn / num_tokens\n",
    "print(f\"The total Cross-Entropy of bigram model via Kneser-Ney smoothing for our Test set is: {cross_entropy_bigram_kn: .3f}\")\n",
    "\n",
    "# Calculation of the perplexity of bigram model for the test set via Kneser-Ney smoothing\n",
    "bigram_perplexity_kn = 2 ** (cross_entropy_bigram_kn)\n",
    "print(f\"Perplexity of bigram model for Test Set: {bigram_perplexity_kn:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJYh-Z8oRFuv"
   },
   "source": [
    "## Calculation of probabilities, Cross-Entropy and Perplexity for our trigram model (Kneser-Ney smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ftYkx1DORIK-",
    "outputId": "c8432862-1360-4c70-f62a-c01bc9ce4f99",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 89223/90000 [00:00<00:00, 275384.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total Cross-Entropy of trigram model for our Test set is:  6.086\n",
      "Perplexity of trigram model for Test Set: 67.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate continuation counts\n",
    "continuation_counts_tri = Counter([trigram[2] for trigram in trigram_counter])\n",
    "\n",
    "total_log_proba_trigram_kn = 0.0\n",
    "delta = 0.5\n",
    "\n",
    "# Convert list of n-grams to a list of tuples\n",
    "ngram_tuples_tri = [tuple(ng) for ng in trigram_counter]\n",
    "\n",
    "# Create a Counter for the prefixes\n",
    "prefixes_counter_tri = Counter(ng[:-1] for ng in ngram_tuples_tri)\n",
    "\n",
    "with tqdm(total=90000) as pbar:  # Check our time and iters remaining!\n",
    "    for sent in cleaned_test_sentences:\n",
    "        padded_sent = ['<s>'] + ['<s>'] + sent + ['<e>']\n",
    "\n",
    "        for first_token, second_token, third_token in windowed(padded_sent, 3):\n",
    "            trigram = (first_token, second_token, third_token)\n",
    "            trigram_prob = calc_kneser_ney_proba(trigram_counter, bigram_counter, continuation_counts_tri,\n",
    "                                                     trigram, delta, prefixes_counter_tri)\n",
    "            if trigram_prob>=1:\n",
    "                print(trigram_prob)\n",
    "            total_log_proba_trigram_kn += math.log2(trigram_prob)\n",
    "            pbar.update(1)  # Update the progress bar\n",
    "\n",
    "cross_entropy_trigram_kn = - total_log_proba_trigram_kn / num_tokens\n",
    "print(f\"The total Cross-Entropy of trigram model for our Test set is: {cross_entropy_trigram_kn: .3f}\")\n",
    "\n",
    "# Calculation of the perplexity of bigram model for the test set\n",
    "trigram_perplexity_kn = 2 ** (cross_entropy_trigram_kn)\n",
    "print(f\"Perplexity of trigram model for Test Set: {trigram_perplexity_kn:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJqSt9uuUGs8"
   },
   "source": [
    "## Autocomplete an incomplete sentence\n",
    "\n",
    "auto......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "m6N1y-SdV3mk"
   },
   "outputs": [],
   "source": [
    "def generate_candidates(state, ngram_counter, model_name):\n",
    "    \"\"\"\n",
    "\n",
    "    :param state:\n",
    "    :param ngram_counter:\n",
    "    :param model_name:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    ngram_width = 1\n",
    "    if model_name == 'trigram':\n",
    "      ngram_width = 2\n",
    "    prev_words = tuple(state[-ngram_width:])\n",
    "\n",
    "    # Find candidates words\n",
    "    next_words = [prev_words_tuple[-1] for prev_words_tuple in ngram_counter if prev_words == tuple(prev_words_tuple[:-1])]\n",
    "    if next_words == []:\n",
    "        if model_name == 'trigram':\n",
    "            if prev_words[0] and prev_words[1] not in vocab:\n",
    "                prev_words = ('<UNK>', '<UNK>',)\n",
    "            elif prev_words[0] not in vocab:\n",
    "                prev_words = ('<UNK>', prev_words[1],)\n",
    "            else:\n",
    "                prev_words = (prev_words[0], '<UNK>',)\n",
    "            if prev_words in prefixes_counter_tri:\n",
    "                next_words = [prev_words_tuple[-1] for prev_words_tuple in ngram_counter if prev_words == tuple(prev_words_tuple[:-1])]\n",
    "                output = [state + [next_word] for next_word in next_words]\n",
    "            else:\n",
    "                 return generate_candidates(state, bigram_counter, 'bigram')\n",
    "        else:\n",
    "            prev_words = ('<UNK>',)\n",
    "            next_words = [prev_words_tuple[-1] for prev_words_tuple in ngram_counter if prev_words == tuple(prev_words_tuple[:-1])]\n",
    "            output = [state + [next_word] for next_word in next_words]\n",
    "    else:\n",
    "        output = [state + [next_word] for next_word in next_words]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "S5DTrsReW3FE"
   },
   "outputs": [],
   "source": [
    "def score(state, vocab_size, ngram_counter, ngram_minus_one_counter, prefixes_count,model_name='trigram', dist=0, l1=1, l2=0,\n",
    "          calculate_ngram_probability_fn=calc_kneser_ney_proba):\n",
    "    \"\"\"\n",
    "\n",
    "    :param state:\n",
    "    :param vocab_size:\n",
    "    :param alpha:\n",
    "    :param ngram_counter:\n",
    "    :param ngram_minus_one_counter:\n",
    "    :param model_name:\n",
    "    :param dist:\n",
    "    :param l1:\n",
    "    :param l2:\n",
    "    :param calculate_ngram_probability_fn:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if model_name == 'trigram':\n",
    "      ngram_width = 3\n",
    "      # Re-assign the correct continuation counts for the respective model\n",
    "      con_counts = continuation_counts_tri\n",
    "    else:\n",
    "       ngram_width = 2\n",
    "\n",
    "      # Re-assign the correct continuation counts for the respective model\n",
    "       con_counts = continuation_counts_bi\n",
    "    probability = 0\n",
    "    prev_words = tuple(state[-ngram_width:])\n",
    "    # for i in range(ngram_width, len(state)):\n",
    "    #     prev_words = tuple(state[i-ngram_width:i+1])\n",
    "    probability += math.log2(l1*calc_kneser_ney_proba(ngram_counter, ngram_minus_one_counter, continuation_counts_bi,\n",
    "                                            prev_words, 0, prefixes_count) + l2 * 1 / (dist + 1))\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "YtC2Kb7FXiRN"
   },
   "outputs": [],
   "source": [
    "def beam_search_sequence(initial_state, max_depth, beam_width, vocab_size, ngram_counter,\n",
    "                         ngram_minus_one_counter, generate_candidates_fn, score_fn):\n",
    "    \"\"\"\n",
    "\n",
    "    :param initial_state:\n",
    "    :param max_depth:\n",
    "    :param beam_width:\n",
    "    :param vocab_size:\n",
    "    :param alpha:\n",
    "    :param ngram_counter:\n",
    "    :param ngram_minus_one_counter:\n",
    "    :param generate_candidates_fn:\n",
    "    :param score_fn:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    candidates = [(initial_state, 0)]\n",
    "\n",
    "    for depth in range(max_depth):\n",
    "        new_candidates = []\n",
    "        for candidate, prob in candidates:\n",
    "            for next_state in generate_candidates_fn(candidate, bigram_counter, 'bigram'):\n",
    "\n",
    "                new_prob = prob + score_fn(next_state, vocab_size, ngram_counter, ngram_minus_one_counter,\n",
    "                                           prefixes_counter_bi,'bigram')\n",
    "\n",
    "                if next_state[-1] == '<UNK>' :\n",
    "                    pass\n",
    "                else:\n",
    "                    new_candidates.append((next_state, new_prob))\n",
    "\n",
    "        new_candidates = sorted(new_candidates, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        candidates = new_candidates[:beam_width]\n",
    "        print(candidates)\n",
    "    best_sequence, best_prob = max(candidates, key=lambda x: x[1])\n",
    "    return best_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oaUKlDyUYV5N",
    "outputId": "ead8c1d7-4e20-4526-a390-e4fb37fdfa6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in train set: 12038\n",
      "[(['report', 'said'], -2.668103736021588), (['report', '.'], -2.9961579337057733), (['report', ','], -3.3219280948875167), (['report', 'on'], -3.9657842846622637), (['report', 'a'], -4.158429362604659)]\n",
      "[(['report', '.', '<e>'], -3.9487711817484517), (['report', 'said', '.'], -4.339014337216016), (['report', 'said', 'it'], -5.334360804545055), (['report', 'said', 'the'], -5.486319009456026), (['report', 'on', 'the'], -6.1389192626523545)]\n",
      "[(['report', 'said', '.', '<e>'], -5.291627585258694), (['report', 'said', '.', 'S'], -8.367540035397306), (['report', 'said', 'it', 'has'], -8.775556500622955), (['report', 'said', 'it', 'said'], -9.020157417425974), (['report', 'said', 'it', 'is'], -9.111864558586156)]\n",
      "[(['report', 'said', '.', 'S', '.'], -8.596795929486536), (['report', 'said', 'it', 'said', '.'], -10.691068018620403), (['report', 'said', '.', '<e>', ','], -10.953088460970571), (['report', 'said', '.', '<e>', '.'], -11.227483688799554), (['report', 'said', 'it', 'has', 'been'], -11.478069056823095)]\n",
      "[(['report', 'said', '.', 'S', '.', '<e>'], -9.549409177529215), (['report', 'said', 'it', 'said', '.', '<e>'], -11.643681266663082), (['report', 'said', '.', '<e>', '.', '<e>'], -12.180096936842233), (['report', 'said', '.', 'S', '.', 'S'], -12.625321627667827), (['report', 'said', '.', 'S', '.', '5'], -13.68990533387802)]\n",
      "[(['report', 'said', '.', 'S', '.', 'S', '.'], -12.854577521757056), (['report', 'said', '.', 'S', '.', '<e>', ','], -15.210870053241091), (['report', 'said', '.', 'S', '.', '<e>', '.'], -15.485265281070074), (['report', 'said', '.', 'S', '.', '5', 'mln'], -15.524892319979655), (['report', 'said', '.', 'S', '.', '5', '.'], -15.880157598741128)]\n",
      "[(['report', 'said', '.', 'S', '.', 'S', '.', '<e>'], -13.807190769799735), (['report', 'said', '.', 'S', '.', '<e>', '.', '<e>'], -16.43787852911275), (['report', 'said', '.', 'S', '.', '5', '.', '<e>'], -16.832770846783806), (['report', 'said', '.', 'S', '.', 'S', '.', 'S'], -16.88310321993835), (['report', 'said', '.', 'S', '.', '5', 'mln', 'dlrs'], -17.641288366515035)]\n",
      "[(['report', 'said', '.', 'S', '.', 'S', '.', 'S', '.'], -17.112359114027576), (['report', 'said', '.', 'S', '.', 'S', '.', '<e>', ','], -19.468651645511613), (['report', 'said', '.', 'S', '.', 'S', '.', '<e>', '.'], -19.743046873340596), (['report', 'said', '.', 'S', '.', 'S', '.', '<e>', 'and'], -20.21520059031986), (['report', 'said', '.', 'S', '.', 'S', '.', '<e>', 'to'], -20.48599693071336)]\n",
      "[(['report', 'said', '.', 'S', '.', 'S', '.', 'S', '.', '<e>'], -18.064972362070254), (['report', 'said', '.', 'S', '.', 'S', '.', '<e>', '.', '<e>'], -20.695660121383273), (['report', 'said', '.', 'S', '.', 'S', '.', 'S', '.', 'S'], -21.140884812208867), (['report', 'said', '.', 'S', '.', 'S', '.', 'S', '.', '5'], -22.20546851841906), (['report', 'said', '.', 'S', '.', 'S', '.', '<e>', ',', '000'], -22.29162685683275)]\n",
      "[(['report', 'said', '.', 'S', '.', 'S', '.', 'S', '.', 'S', '.'], -21.370140706298095), (['report', 'said', '.', 'S', '.', 'S', '.', 'S', '.', '<e>', ','], -23.726433237782132), (['report', 'said', '.', 'S', '.', 'S', '.', 'S', '.', '<e>', '.'], -24.000828465611114), (['report', 'said', '.', 'S', '.', 'S', '.', 'S', '.', '5', 'mln'], -24.040455504520697), (['report', 'said', '.', 'S', '.', 'S', '.', '<e>', ',', '000', 'vs'], -24.29918684814561)]\n",
      "The 10 best words for autocomplete the sentence \"The rafail report\" is: \n",
      "The rafail report said . S . S . S . S .\n"
     ]
    }
   ],
   "source": [
    "# Build the vocab\n",
    "vocab = [word[0] for word in unigram_counter]\n",
    "print(f'Number of tokens in train set: {len(vocab)}')\n",
    "\n",
    "test_sentence = \"The report\"\n",
    "initial_state = test_sentence.split(' ')[-1:]\n",
    "max_depth = 10\n",
    "beam_width = 5\n",
    "best_sequence = beam_search_sequence(initial_state, max_depth, beam_width,len(vocab),bigram_counter,unigram_counter, generate_candidates, score)\n",
    "\n",
    "print(f'The 10 best words for autocomplete the sentence \"{test_sentence}\" is: ')\n",
    "print(test_sentence, ' '.join(best_sequence[1:]))  # Excluding the \"<start>\" token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBmVDe4s89w-",
    "outputId": "dfa8861d-99d6-44e3-b6f8-2f97abb7dff6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4912"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JXL5zYXd1nPP",
    "outputId": "fb0a65b2-3a49-4f02-fe86-5a4cb1110750"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_counter[(\"that\",\"they\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ergDq7hWZUAY"
   },
   "source": [
    "## Autocomplete with a trigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kE6yTrEvZZ2N",
    "outputId": "6ee07845-e2d2-4035-e6b3-6fd1f368725d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "says that later in the U . S . Agriculture Department said . <e> <e> and , in a statement . <e>\n"
     ]
    }
   ],
   "source": [
    "def beam_search_decode(initial_state, max_depth, beam_width, generate_candidates_fn, score_fn):\n",
    "    \"\"\"\n",
    "\n",
    "    :param initial_state:\n",
    "    :param max_depth:\n",
    "    :param beam_width:\n",
    "    :param generate_candidates_fn:\n",
    "    :param score_fn:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    candidates = [(initial_state, 0)]\n",
    "\n",
    "    for depth in range(max_depth):\n",
    "        new_candidates = []\n",
    "        for candidate, prob in candidates:\n",
    "            for next_state in generate_candidates_fn(candidate, trigram_counter, 'trigram'):\n",
    "                new_prob = prob + score_fn(next_state, len(vocab), trigram_counter, bigram_counter,\n",
    "                                           prefixes_counter_tri,'trigram')\n",
    "\n",
    "\n",
    "                if next_state[-1] == '<UNK>' :\n",
    "                    pass\n",
    "                else:\n",
    "                    new_candidates.append((next_state, new_prob))\n",
    "\n",
    "\n",
    "        new_candidates = sorted(new_candidates, key=lambda x: x[1], reverse=True)\n",
    "        candidates = new_candidates[:beam_width]\n",
    "\n",
    "    best_sequence, best_prob = max(candidates, key=lambda x: x[1])\n",
    "    return best_sequence\n",
    "\n",
    "\n",
    "test_sentence = \"The report says that\"\n",
    "initial_state = test_sentence.split(' ')[-2:]\n",
    "max_depth = 20\n",
    "beam_width = 3\n",
    "best_sequence = beam_search_decode(initial_state, max_depth, beam_width, generate_candidates, score)\n",
    "print(' '.join(best_sequence))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMUGmRqt1nPP"
   },
   "outputs": [],
   "source": [
    "prefixes_counter_tri['of', 'whom',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1B6S4LUG1nPP"
   },
   "outputs": [],
   "source": [
    "trigram_counter['the', '<UNK>','is']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vM9qlzd9aBXV"
   },
   "source": [
    "## iv) Develop a context-aware spelling corrector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "xb39Iak4aCYK"
   },
   "outputs": [],
   "source": [
    "# Leveinstein Destance with transposition.\n",
    "def damerau_levenshtein_distance(s1, s2):\n",
    "    \"\"\"\n",
    "    Calculate the Damerau–Levenshtein distance between two strings.\n",
    "\n",
    "    Parameters:\n",
    "    - s1: first string\n",
    "    - s2: second string\n",
    "\n",
    "    Returns:\n",
    "    - Damerau Levenshtein distance\n",
    "    \"\"\"\n",
    "    len_s1 = len(s1)\n",
    "    len_s2 = len(s2)\n",
    "    d = [[0] * (len_s2 + 1) for _ in range(len_s1 + 1)]\n",
    "\n",
    "    for i in range(len_s1 + 1):\n",
    "        d[i][0] = i\n",
    "    for j in range(len_s2 + 1):\n",
    "        d[0][j] = j\n",
    "\n",
    "    for i in range(1, len_s1 + 1):\n",
    "        for j in range(1, len_s2 + 1):\n",
    "            cost = 0 if s1[i - 1] == s2[j - 1] else 1\n",
    "            d[i][j] = min(\n",
    "                d[i - 1][j] + 1,  # deletion\n",
    "                d[i][j - 1] + 1,  # insertion\n",
    "                d[i - 1][j - 1] + cost,  # substitution\n",
    "            )\n",
    "            if i > 1 and j > 1 and s1[i - 1] == s2[j - 2] and s1[i - 2] == s2[j - 1]:\n",
    "                d[i][j] = min(d[i][j], d[i - 2][j - 2] + cost)  # transposition\n",
    "\n",
    "    return d[len_s1][len_s2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nf4ORytJaMrE",
    "outputId": "5274332b-84d2-443c-b0d7-251826702931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate words for 'apqlicathoo' is: \n",
      "application | applications | allocation | acquisition | appreciation | liquidation | association | location | indicator | utilization | "
     ]
    }
   ],
   "source": [
    "# Take a word and the vocab and produce candidates/\n",
    "def generate_candidate_with_distance(state, word, word_list, max_candidates=20, distance_fn=damerau_levenshtein_distance):\n",
    "    \"\"\"\n",
    "    Generate candidate words for a misspelled word, using between words distance.\n",
    "\n",
    "    Parameters:\n",
    "    - state: The current state.\n",
    "    - word: The misspelled word.\n",
    "    - word_list: List of words to search for candidates.\n",
    "    - max_candidates: Maximum number of candidates\n",
    "    - distance_fn: Distance function. Deffault damerau_levenshtein_distance\n",
    "\n",
    "    Returns:\n",
    "    - A list of candidate words.\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "\n",
    "    for candidate in word_list:\n",
    "        distance = distance_fn(word, candidate)\n",
    "\n",
    "        candidates.append((candidate, distance))\n",
    "\n",
    "    # Sort candidates by Distance distance in ascending order\n",
    "    candidates.sort(key=lambda x: x[1])\n",
    "    next_words = candidates[:max_candidates]\n",
    "\n",
    "    # Return next word and distance\n",
    "    return [(state + [next_word[0]], next_word[1]) for next_word in next_words]\n",
    "\n",
    "# Example usage\n",
    "misspelled_word = \"apqlicathoo\"\n",
    "initial_state = ['<s>','<s>']\n",
    "candidates = generate_candidate_with_distance(initial_state,misspelled_word, vocab, 10)\n",
    "print(f\"Candidate words for '{misspelled_word}' is: \")\n",
    "for cand in candidates:\n",
    "  print(cand[0][2], end=\" | \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NCoH8MwEb9yX",
    "outputId": "3d2507cf-5a3c-47c1-867a-4a9b1117f12b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 0.1\n",
      "[(['<s>', '<s>', 'The'], -2.0296607112181833), (['<s>', '<s>', 'He'], -4.055983688419189), (['<s>', '<s>', 'They'], -4.123348515338661), (['<s>', '<s>', 'She'], -4.2943940566748875), (['<s>', '<s>', 'the'], -4.317865751845653)]\n",
      "[(['<s>', '<s>', 'The', 'department'], -6.924611532843555), (['<s>', '<s>', 'The', 'report'], -6.962695392614918), (['<s>', '<s>', 'The', 'deposit'], -7.334842842990012), (['<s>', '<s>', 'The', 'part'], -7.3515888061055445), (['<s>', '<s>', 'The', 'separate'], -7.351588806105546)]\n",
      "[(['<s>', '<s>', 'The', 'department', 'office'], -10.246539627730915), (['<s>', '<s>', 'The', 'report', 'office'], -10.28462348750228), (['<s>', '<s>', 'The', 'deposit', 'office'], -10.656770937877331), (['<s>', '<s>', 'The', 'part', 'office'], -10.6726640630465), (['<s>', '<s>', 'The', 'separate', 'office'], -10.6726640630465)]\n",
      "[(['<s>', '<s>', 'The', 'department', 'office', 'reports'], -14.565955540401294), (['<s>', '<s>', 'The', 'report', 'office', 'reports'], -14.60403940017266), (['<s>', '<s>', 'The', 'deposit', 'office', 'reports'], -14.97618685054771), (['<s>', '<s>', 'The', 'part', 'office', 'reports'], -14.99207997571688), (['<s>', '<s>', 'The', 'separate', 'office', 'reports'], -14.99207997571688)]\n",
      "The corrected sentence is: The department office reports\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def beam_search_spelling(sentence, beam_width, l1, l2, generate_candidates_fn, score_fn):\n",
    "    \"\"\"\n",
    "    Spelling correction with contect awereness using beam search\n",
    "\n",
    "    Parameters:\n",
    "    - sentence: The sentence we try to correct\n",
    "    - beam_width: The width of beam search algorithm.\n",
    "    - generate_candidates_fn: function that generates candidate words\n",
    "    - score_fn: Function that calculates the log probability\n",
    "\n",
    "    Returns:\n",
    "    - The most probable sequence corrected.\n",
    "    \"\"\"\n",
    "    print(l1,l2)\n",
    "    initial_state = ['<s>','<s>']\n",
    "    candidates = [(initial_state, 0)]\n",
    "    # sentence = word_tokenize(sentence)\n",
    "    max_depth = len(sentence)\n",
    "    for depth in range(max_depth):\n",
    "        new_candidates = []\n",
    "        for candidate, prob in candidates:\n",
    "            for next_state, dist in generate_candidates_fn(candidate, sentence[depth],vocab):\n",
    "\n",
    "                # Prob we add the previous prob, the prob of the next state and the inverse of the distance\n",
    "                new_prob = prob + score_fn(next_state,len(vocab), trigram_counter, bigram_counter, prefixes_counter_tri,'trigram', dist, l1, l2)\n",
    "\n",
    "                new_candidates.append((next_state, new_prob))\n",
    "\n",
    "\n",
    "        new_candidates = sorted(new_candidates, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        candidates = new_candidates[:beam_width]\n",
    "        print(candidates)\n",
    "    best_sequence, best_prob = max(candidates, key=lambda x: x[1])\n",
    "    return best_sequence[2:]\n",
    "\n",
    "\n",
    "test_sentence = word_tokenize(\"The deparmt office reprts \")\n",
    "beam_width = 5\n",
    "best_sequence = beam_search_spelling(test_sentence, beam_width, 0.9, 0.1, generate_candidate_with_distance, score)\n",
    "print(\"The corrected sentence is\", end=': ')\n",
    "print(' '.join(best_sequence))  # Excluding the \"<start>\" token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lkt67oCH01zi",
    "outputId": "cba2466e-19af-4e06-c044-f6a42e4c2825"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INjMi9hZcuBY"
   },
   "source": [
    "## v) Evaluate your context-aware spelling corrector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LmGm8gBrcklj",
    "outputId": "fe2c28bf-8ab2-4929-8fa1-2dde4f0d0459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'colmisshon', 'is', 'expacted', 'to', 'approva', 'uhe', 'apqlicathoo', 'at', 'a', 'meeting', 'tomorrow', '.']\n",
      "______________________\n",
      "['\"', 'The', 'Unhteb', 'Stater', 'and', 'the', 'siy', 'major', 'hndustrial', 'countries', 'are', 'fully', 'committed', 'to', 'implementing', 'nur', 'undertekings', 'hn', 'these', 'afreements', ',\"', 'Baker', 'told', 'tie', 'meetings', '.']\n",
      "______________________\n",
      "['Soo', 'Line', 'saib', 'in', 'January', 'it', 'vas', 'saejing', 'dids', 'for', 'the', 'qroparty', '.']\n",
      "______________________\n",
      "['Cain', '-', 'Sloan', 'has', 'four', 'stnres', 'in', 'Nashville', '.']\n",
      "______________________\n",
      "['Romero', 'saib', 'he', 'would', 'tell', 'big', 'duxars', 'nf', 'cnqra', 'meal', 'in', 'London', 'tiat', 'the', 'Philippioes', 'was', 'doing', 'its', 'best', 'to', 'meet', 'EC', 'stanbards', '.']\n",
      "______________________\n",
      "['Pretax', 'profius', 'also', 'dipped', 'to', '601', '.', '7', 'lln', 'stg', 'after', '614', '.', '4', 'mln', '.']\n",
      "______________________\n",
      "['Asked', 'hn', 'ao', 'interview', 'hf', 'it', 'was', 'tile', 'to', 'consider', 'a', 'marketinf', 'loan', 'for', 'soybeans', ',', 'Lyng', 'saib', ',', '\"', 'I', 'don', \"'\", 't', 'thiok', 'so', '.']\n",
      "______________________\n",
      "['In', 'January', 'retail', 'prices', 'rose', '6', '.', '6', 'pet', 'from', 'December', 'to', 'stand', '90', '.', '4', 'pct', 'higher', 'then', 'in', 'Januarx', '1986', '.']\n",
      "______________________\n",
      "['AGENCY', 'HEAD', 'SAYS', 'JAPAN', 'SHOULD', 'CUT', 'RICE', 'PRICE', 'The', 'government', 'should', 'cut', 'its', 'consular', 'rice', 'price', 'if', 'the', 'official', 'probucer', 'prhce', 'is', 'reduced', 'naxt', 'mnnth', ',', 'Tetsuo', 'Kondo', ',', 'direcuor', 'general', 'of', 'tie', 'govesnmeot', \"'\", 's', 'Eeonomhc', 'Planning', 'Agency', '(', 'EPA', '),', 'told', 'reporters', '.']\n",
      "______________________\n",
      "['The', 'deal', 'included', 'the', 'micanse', 'for', 'Visa', 'credhu', 'cards', '.']\n",
      "______________________\n",
      "['This', 'brought', 'combined', 'wieat', 'eod', 'basley', 'exports', 'rince', 'uhe', 'raason', 'started', 'on', 'July', '1', 'to', '7', '.', '60', 'mln', 'tonnar', ',', 'substantially', 'up', 'on', 'tha', '4', '.', '02', 'mln', 'axported', 'hn', 'the', 'same', '1985', '/', '86', 'period', '.']\n",
      "______________________\n",
      "['\"', 'We', 'oeed', 'time', 'for', 'those', 'ections', 'and', 'tha', 'earlier', 'deprecieuion', 'uo', 'vork', 'their', 'effects', ',\"', 'he', 'said', '.']\n",
      "______________________\n",
      "['Whhle', 'the', 'measure', 'does', 'not', 'dind', 'Reagan', 'to', 'eny', 'action', ',', 'Senata', 'leaders', 'said', 'iur', 'adoption', 'would', 'warn', 'Japan', 'stifger', 'legismathon', 'would', 'be', 'cnnsidesed', 'ig', 'the', 'violations', 'continue', '.']\n",
      "______________________\n",
      "['Expansion', 'bx', 'tha', 'Japanese', 'firm', ',', 'said', 'analysts', 'polmed', 'by', 'Reuters', '.']\n",
      "______________________\n",
      "['Iu', 'was', 'down', 'over', 'three', 'points', 'Wednesday', 'morning', 'before', 'closinf', 'down', '7', '/', '8', '.']\n",
      "______________________\n",
      "['\"', 'That', 'pattern', 'is', 'starting', 'and', 'vhll', 'contioue', 'for', 'a', 'numdes', 'of', 'xears', ',\"', 'Chhmerine', 'said', '.']\n",
      "______________________\n",
      "['\"', 'I', 'don', \"'\", 't', 'think', 'management', 'was', 'lookiog', 'for', 'a', 'buyes', 'hn', 'any', 'way', 'before', 'this', 'offes', ',\"', 'ie', 'said', '.']\n",
      "______________________\n",
      "['NORTHWEST', 'TELEPRODUCTIONS', '&', 'lt', ';', 'NWTL', '.', 'O', '>', '4TH', 'QTR', 'NET', 'Shr', '15', 'cts', 'vs', '16', 'ets', 'Net', '239', ',', '034', 'vr', '264', ',', '485', 'Sales', '2', ',', '932', ',', '782', 'vs', '2', ',', '664', ',', '853', 'Year', 'Shr', '57', 'cts', 'vs', '45', 'cts', 'Net', '929', ',', '524', 'vs', '741', ',', '121', 'Saler', '10', '.', '9', 'mln', 'vs', '9', ',', '708', ',', '792']\n",
      "______________________\n",
      "['\"', 'We', 'are', 'nnt', 'trying', 'tn', 'sell', 'tha', 'eompanx', '.']\n",
      "______________________\n",
      "['The', 'U', '.', 'S', '.', 'roybean', 'industry', 'delieves', 'labels', 'indicating', 'trophcal', 'oils', 'are', 'high', 'in', 'sattreted', 'fats', 'wnuld', 'discouraga', 'consumption', 'of', 'the', 'oims', ',', 'imported', 'psimarily', 'grol', 'Malaysia', ',', 'Inbonasia', 'and', 'the', 'Philipqhnes', '.']\n",
      "______________________\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def replace_characters(sentence, probability):\n",
    "    modified_sentence = []\n",
    "    for word in sentence:\n",
    "        modified_word = ''\n",
    "        for char in word:\n",
    "            if char != ' ' and random.random() < probability:\n",
    "                # Replace non-space character with a visually or acoustically similar character\n",
    "                # You can customize this part based on your preference or use external libraries for similarity\n",
    "                modified_char = get_similar_char(char)\n",
    "                modified_word += modified_char\n",
    "            else:\n",
    "                modified_word += char\n",
    "        modified_sentence.append(modified_word)\n",
    "    return modified_sentence\n",
    "\n",
    "def get_similar_char(char):\n",
    "    # Replace this with your logic to get a visually or acoustically similar character\n",
    "    # For simplicity, using a basic example here (you can expand this based on your requirements)\n",
    "    similar_chars = {'a': 'e', 'b': 'd', 'c': 'e', 'd': 'b', 'e': 'a', 'f': 'g',\n",
    "                     'g': 'f', 'h': 'i', 'i': 'h', 'j': 'k', 'k': 'j', 'l': 'm',\n",
    "                     'm': 'l', 'n': 'o', 'o': 'n', 'p': 'q', 'q': 'p', 'r': 's',\n",
    "                     's': 'r', 't': 'u', 'u': 't', 'v': 'w', 'w': 'v', 'x': 'y',\n",
    "                     'y': 'x', 'z': 'z'}\n",
    "    return similar_chars.get(char, char)\n",
    "\n",
    "def modify_corpus(corpus, probability):\n",
    "    modified_corpus = []\n",
    "    for sentence in corpus:\n",
    "        modified_sentence = replace_characters(sentence, probability)\n",
    "        modified_corpus.append(modified_sentence)\n",
    "    return modified_corpus\n",
    "\n",
    "# Example usage with a probability of 0.1 (10% chance of replacing each non-space character)\n",
    "modified_test_corpus = modify_corpus(test_sents, 0.1)\n",
    "\n",
    "print_cnt = 0\n",
    "for sent in modified_test_corpus:\n",
    "  print_cnt +=1\n",
    "  print(sent)\n",
    "  print(\"______________________\")\n",
    "  if print_cnt == 20:\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6YKZzyTkdJej",
    "outputId": "13455cea-e830-4432-fd76-7301b04a2807"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_sents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Take a portion of the test_corpus and modified_test_corpus\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m org_sent \u001b[38;5;241m=\u001b[39m \u001b[43mtest_sents\u001b[49m[:\u001b[38;5;241m5\u001b[39m]\n\u001b[0;32m      5\u001b[0m wrg_sent \u001b[38;5;241m=\u001b[39m modified_test_corpus[:\u001b[38;5;241m5\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcorrect_corpus_np\u001b[39m(corpus, vocab, max_candidates\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_sents' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Take a portion of the test_corpus and modified_test_corpus\n",
    "org_sent = cleaned_test_sentences[:5]\n",
    "wrg_sent = modified_test_corpus[:5]\n",
    "\n",
    "def correct_corpus_np(corpus, vocab, max_candidates=5):\n",
    "    corrected_corpus = []\n",
    "    for sentence in corpus:\n",
    "        corrected_sentence = beam_search_spelling(sentence, 3,0.2,0.8, generate_candidate_with_distance, score)\n",
    "        corrected_corpus.append(corrected_sentence)\n",
    "    return corrected_corpus\n",
    "\n",
    "corrected_test_corpus = correct_corpus_np(wrg_sent, vocab, 5)\n",
    "\n",
    "print(\"Original Test Corpus:\")\n",
    "print(org_sent)\n",
    "\n",
    "print(\"\\nModified Test Corpus:\")\n",
    "print(wrg_sent)\n",
    "\n",
    "print(\"\\nCorrected Test Corpus:\")\n",
    "print(corrected_test_corpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlhtYwTZdO7X"
   },
   "source": [
    "## Evaluate the context-aware spelling corrector in terms of Word Error Rate (WER) and Character Error Rate (CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpi-XeZIdWi8",
    "outputId": "52acdf33-95fc-4937-e6ec-0f64d756522a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER score corrected vs original is: 0.10588235294117647\n",
      "WER score artificial vs original is: 0.3176470588235294\n",
      "CER score corrected vs original is: 0.04680851063829787\n",
      "CER score wrong vs original is: 0.07659574468085106\n"
     ]
    }
   ],
   "source": [
    "# !pip install evaluate\n",
    "# !pip install jiwer\n",
    "from evaluate import load\n",
    "\n",
    "cor_sent = corrected_test_corpus[:50]\n",
    "\n",
    "# Flatten the list of lists\n",
    "flattened_cor_sent = [' '.join(sentence) for sentence in cor_sent]\n",
    "flattened_org_sent = [' '.join(sentence) for sentence in org_sent]\n",
    "flattened_wrg_sent =  [' '.join(sentence) for sentence in wrg_sent]\n",
    "# Transform predictions\n",
    "predictions1 = [' '.join(flattened_cor_sent)]\n",
    "\n",
    "references = [' '.join(flattened_org_sent)]\n",
    "\n",
    "predictions2 = [' '.join(flattened_wrg_sent)]\n",
    "\n",
    "wer1 = load(\"wer\")  # Load Word-Error-Rate metric\n",
    "wer_score = wer1.compute(predictions=predictions1, references=references)\n",
    "print(f\"WER score corrected vs original is: {wer_score}\")\n",
    "\n",
    "\n",
    "wer2 = load(\"wer\")  # Load Word-Error-Rate metric\n",
    "wer_score = wer2.compute(predictions=predictions2, references=references)\n",
    "print(f\"WER score artificial vs original is: {wer_score}\")\n",
    "\n",
    "\n",
    "cer1 = load(\"cer\")\n",
    "cer_score = cer1.compute(predictions=predictions1, references=references)\n",
    "print(f\"CER score corrected vs original is: {cer_score}\")\n",
    "\n",
    "\n",
    "cer2 = load(\"cer\")\n",
    "cer_score = cer2.compute(predictions=predictions2, references=references)\n",
    "print(f\"CER score wrong vs original is: {cer_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QWtNXlyp3a0Z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

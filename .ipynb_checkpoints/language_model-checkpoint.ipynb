{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zrl3_S9Jfb3_"
      },
      "source": [
        "EXERCISE 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvgPsv5ucrng",
        "outputId": "066181c2-f18c-4c34-ff79-30e158a57508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gel3iPn3E_0y",
        "outputId": "81739522-4788-422e-ddf5-2ec6a12a976f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('reuters')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import reuters\n",
        "from nltk.probability import FreqDist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "import math\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "neT2UJDQc1ep"
      },
      "outputs": [],
      "source": [
        "# Load the 'reuters' corpus\n",
        "sentences = reuters.sents()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZuhIg9dhF6q6"
      },
      "outputs": [],
      "source": [
        "# Splitting data into Training, Development and Test set\n",
        "train_sents, test_sents = train_test_split(reuters.sents(), test_size=0.3, random_state=42)\n",
        "dev_sents, test_sents = train_test_split(test_sents, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXQ0qcPfGVHd",
        "outputId": "efdbdfdf-eba8-4a3e-f0ec-f884e85a32f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences in train set: 38301\n"
          ]
        }
      ],
      "source": [
        "print(f'Number of sentences in train set: {len(train_sents)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JJOZUMljGS2x"
      },
      "outputs": [],
      "source": [
        "# Transform the train sentences into words\n",
        "train_words = [word for sentence in train_sents for word in sentence]\n",
        "freq_dist_train = FreqDist(train_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4EKxyX82Jc55"
      },
      "outputs": [],
      "source": [
        "cleaned_train_sentences = []\n",
        "for sentence in train_sents:\n",
        "    cleaned_train_sentence = [word if freq_dist_train[word] > 5 else '<UNK>' for word in sentence]\n",
        "    cleaned_train_sentences.append(cleaned_train_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building again the train_words now that we have <UNK>"
      ],
      "metadata": {
        "id": "n-ASkCzyqYXy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8PPQ4TKeOsb",
        "outputId": "0c294f6c-fb97-4c42-fb65-b624f2179f1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(('.',), 66403),\n",
            " ((',',), 50713),\n",
            " (('<UNK>',), 47297),\n",
            " (('the',), 41011),\n",
            " (('of',), 25252),\n",
            " (('to',), 23930),\n",
            " (('in',), 18595),\n",
            " (('and',), 17693),\n",
            " (('said',), 17659),\n",
            " (('a',), 16401)]\n",
            "[(('.', '<e>'), 34142),\n",
            " ((',', '000'), 7220),\n",
            " ((\"'\", 's'), 6427),\n",
            " (('<s>', 'The'), 6167),\n",
            " (('lt', ';'), 6057),\n",
            " (('&', 'lt'), 6055),\n",
            " (('<s>', '<UNK>'), 5776),\n",
            " (('said', '.'), 5581),\n",
            " (('of', 'the'), 4771),\n",
            " (('in', 'the'), 4555)]\n",
            "[(('.', '<e>', '<e>'), 34142),\n",
            " (('<s>', '<s>', 'The'), 6167),\n",
            " (('&', 'lt', ';'), 6054),\n",
            " (('<s>', '<s>', '<UNK>'), 5776),\n",
            " (('said', '.', '<e>'), 5580),\n",
            " (('lt', ';', '<UNK>'), 4256),\n",
            " (('U', '.', 'S'), 3977),\n",
            " (('.', 'S', '.'), 3726),\n",
            " ((';', '<UNK>', '>'), 2701),\n",
            " (('<s>', '<s>', '\"'), 2528)]\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "from nltk.util import ngrams\n",
        "from pprint import pprint\n",
        "\n",
        "unigram_counter = Counter()\n",
        "bigram_counter = Counter()\n",
        "trigram_counter = Counter()\n",
        "\n",
        "for sent in cleaned_train_sentences:\n",
        "    # Is there any need for 'left_pad_symbol' and 'right_pad_symbol'...?\n",
        "    unigram_counter.update([gram for gram in ngrams(sent, 1, pad_left=True, pad_right=True,\n",
        "                                                   left_pad_symbol='<s>',right_pad_symbol='<e>') ])\n",
        "    bigram_counter.update([gram for gram in ngrams(sent, 2, pad_left=True, pad_right=True,\n",
        "                                                   left_pad_symbol='<s>',right_pad_symbol='<e>') ])\n",
        "    trigram_counter.update([gram for gram in ngrams(sent, 3, pad_left=True, pad_right=True,\n",
        "                                                   left_pad_symbol='<s>',right_pad_symbol='<e>') ])\n",
        "pprint(unigram_counter.most_common(10))\n",
        "pprint(bigram_counter.most_common(10))\n",
        "pprint(trigram_counter.most_common(10))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the vocab\n",
        "vocab = [word[0] for word in unigram_counter]\n",
        "print(f'Number of tokens in train set: {len(vocab)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVkKXuwbsFWJ",
        "outputId": "c9da698a-7100-46df-aa22-0f1d46d7c7c5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens in train set: 10521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "UNIGRAM MODEL"
      ],
      "metadata": {
        "id": "wwChyukHusZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the trigram model\n",
        "def create_unigram_model(unigram_counter):\n",
        "    unigram_model = {}\n",
        "    coprus_size = len(train_words)\n",
        "    vocab_size = len(vocab)\n",
        "    alpha = 0.5\n",
        "\n",
        "    # Populate the bigram_model with probabilities\n",
        "    for unigram in unigram_counter:\n",
        "        unigram_model[unigram] = math.log2((unigram_counter.get((unigram),0)+alpha) / (coprus_size + (alpha*vocab_size)))\n",
        "    return unigram_model"
      ],
      "metadata": {
        "id": "ZmBGsuQKurnt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_model = create_unigram_model(unigram_counter)"
      ],
      "metadata": {
        "id": "VRZtnM53vpvc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBvrUAjtuuCd"
      },
      "source": [
        "BUILDING BIGRAM MODEL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "def create_bigram_model(bigram_counter,unigram_counter):\n",
        "    bigram_model = {}\n",
        "    vocab_size = len(vocab)\n",
        "    alpha = 0.01\n",
        "\n",
        "    # Populate the bigram_model with probabilities\n",
        "    for bigram in bigram_counter:\n",
        "        bigram_model[bigram] = math.log2((bigram_counter.get((bigram),0)+alpha) / (unigram_counter.get((bigram[1],),0) + (alpha*vocab_size)))\n",
        "\n",
        "    return bigram_model"
      ],
      "metadata": {
        "id": "Ma0Rj2g-xNka"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_model = create_bigram_model(bigram_counter,unigram_counter)"
      ],
      "metadata": {
        "id": "CKq1EYCExNmb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4YfGu6BsxNp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5MiF-7hYFqy"
      },
      "source": [
        "BUILDING TRIGRAM MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uad7WDEEpFgz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GI7lazXYMiCF"
      },
      "outputs": [],
      "source": [
        "# Building the trigram model\n",
        "def create_trigram_model(trigram_counter,bigram_counter,unigram_counter):\n",
        "    trigram_model = {}\n",
        "    vocab_size = len(vocab)\n",
        "    alpha = 0.01\n",
        "\n",
        "    # Populate the bigram_model with probabilities\n",
        "    for trigram in trigram_counter:\n",
        "        trigram_model[trigram] = math.log2((trigram_counter.get((trigram),0)+alpha) / (bigram_counter.get((trigram[0],trigram[1],),0) + (alpha*vocab_size)))\n",
        "    return trigram_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ItBJVa_duth8"
      },
      "outputs": [],
      "source": [
        "trigram_model = create_trigram_model(trigram_counter,bigram_counter,unigram_counter)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "78ke7BOauOe7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4jwi_cIb1Z4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INTERPOLATION ?"
      ],
      "metadata": {
        "id": "bvKItcywxVsv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAcHJ47esLTC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcztfvfTeOuq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8V799cLPeOyT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tybl8QbFMu8O",
        "outputId": "b0b6fdb7-d175-423d-ea61-bab9756e37d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Entropy: 6.181\n",
            "perplexity: 72.568\n"
          ]
        }
      ],
      "source": [
        "# from itertools import pairwise\n",
        "\n",
        "# sum_prob = 0\n",
        "# bigram_cnt = 0\n",
        "\n",
        "# for sent in cleaned_train_sentences:\n",
        "#     sent = ['<s>'] + sent + ['<e>']\n",
        "\n",
        "#     # Iterate over the bigrams of the sentence\n",
        "#     for first_token, second_token in pairwise(sent):\n",
        "#         bigram_prob = (bigram_counter[(first_token, second_token)] + alpha) / (unigram_counter[(first_token,)] + alpha*vocab_size)\n",
        "#         sum_prob += math.log2(bigram_prob)\n",
        "#         bigram_cnt += 1\n",
        "\n",
        "# HC = -sum_prob / bigram_cnt\n",
        "# perpl = math.pow(2, HC)\n",
        "# print(\"Cross Entropy: {0:.3f}\".format(HC))\n",
        "# print(\"perplexity: {0:.3f}\".format(perpl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdzIrSWXNeY3",
        "outputId": "4e437e27-4bed-4c97-e2dc-e98a76d4e8e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Entropy: 6.557\n",
            "perplexity: 94.133\n"
          ]
        }
      ],
      "source": [
        "# from more_itertools import windowed\n",
        "\n",
        "# sum_prob = 0\n",
        "# trigram_cnt = 0\n",
        "\n",
        "# for sent in cleaned_train_sentences:\n",
        "#     sent = ['<s>'] + ['<s>'] + sent + ['<e>']\n",
        "\n",
        "#     for first_token, second_token, third_token in windowed(sent, n=3):\n",
        "#         trigram_prob = (trigram_counter[(first_token, second_token, third_token)] + alpha) / (bigram_counter[(first_token, second_token)] + alpha*vocab_size)\n",
        "#         sum_prob += math.log2(trigram_prob)\n",
        "#         trigram_cnt+=1\n",
        "\n",
        "# HC = -sum_prob / trigram_cnt\n",
        "# perpl = math.pow(2,HC)\n",
        "# print(\"Cross Entropy: {0:.3f}\".format(HC))\n",
        "# print(\"perplexity: {0:.3f}\".format(perpl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlD4XBUPO3_a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BIGRAM GENERATE NEXT WORD GIVEN SEQUENCE"
      ],
      "metadata": {
        "id": "HeiZ85umgr0o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "likIV0IeV-xe"
      },
      "outputs": [],
      "source": [
        "def generate_candidates(state):\n",
        "    # Given state , generate possible next words\n",
        "    last_word = state[-1]\n",
        "    # Find candidates words\n",
        "    next_words = [word for (prev_word, word) in bigram_model if prev_word == last_word]\n",
        "    return [state + [next_word] for next_word in next_words]\n",
        "\n",
        "def score(state):\n",
        "    # Calculate the probability of the word sequence using the bigram model\n",
        "    probability = 1.0\n",
        "    for i in range(1, len(state)):\n",
        "        prev_word, word = state[i-1], state[i]\n",
        "        probability += bigram_model.get((prev_word, word), 0.0)\n",
        "    return probability\n",
        "\n",
        "def beam_search_decode(initial_state, max_depth, beam_width, generate_candidates_fn, score_fn):\n",
        "    candidates = [(initial_state, 1.0)]\n",
        "\n",
        "    for depth in range(max_depth):\n",
        "        new_candidates = []\n",
        "        for candidate, prob in candidates:\n",
        "            for next_state in generate_candidates_fn(candidate):\n",
        "                new_prob = prob * score_fn(next_state)\n",
        "                new_candidates.append((next_state, new_prob))\n",
        "\n",
        "\n",
        "        # print('\\n***** NEW candidates *****')\n",
        "        # pprint(new_candidates)\n",
        "        new_candidates = sorted(new_candidates, key=lambda x: x[1], reverse=True)\n",
        "        # pprint('***** Sorted')\n",
        "        # pprint(new_candidates)\n",
        "        # print(f'***** Chosen candidates (top-{beam_width})')\n",
        "        candidates = new_candidates[:beam_width]\n",
        "        # pprint(candidates)\n",
        "\n",
        "    best_sequence, best_prob = max(candidates, key=lambda x: x[1])\n",
        "    return best_sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVDoVPgvOfSN",
        "outputId": "aae2fc84-66d2-49a8-8ae6-1ebb32c1d799"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best sequence: ['keep', 'to', 'buy', '.', 'O', 'in', 'February', 'the', 'same', 'the']\n"
          ]
        }
      ],
      "source": [
        "test_sentence = \" I would like to\"\n",
        "initial_state = test_sentence.split(' ')[-1:]\n",
        "max_depth = 10\n",
        "beam_width = 5\n",
        "best_sequence = beam_search_decode(initial_state, max_depth, beam_width, generate_candidates, score)\n",
        "\n",
        "print(\"Best sequence:\", best_sequence[1:])  # Excluding the \"<start>\" token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPjHl2ZxQchc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRIGRAM GENERATE NEXT WORD GIVEN SEQUENCE"
      ],
      "metadata": {
        "id": "VTH1r3lUgydK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixDidm1IQw69"
      },
      "outputs": [],
      "source": [
        "#TRIGRAM MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjrZADxDXTtp",
        "outputId": "8235a419-9a4a-4684-a318-7256514e3728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I would like to\n",
            "see the trade deficit , which is expected to be <UNK> by the U . S . Agriculture Department said\n"
          ]
        }
      ],
      "source": [
        "def generate_candidates(state):\n",
        "    # Given state , generate possible next words\n",
        "    second_word = state[-2]\n",
        "    last_word = state[-1]\n",
        "    # Find candidates words\n",
        "    next_words = [word for (prev_prev_word, prev_word, word) in trigram_model if (prev_word == last_word and prev_prev_word==second_word)]\n",
        "    return [state + [next_word] for next_word in next_words]\n",
        "\n",
        "def score(state):\n",
        "    # Calculate the probability of the word sequence using the bigram model\n",
        "    probability = 0\n",
        "    for i in range(1, len(state)):\n",
        "        prev_prev_word, prev_word, word = state[i-2], state[i-1], state[i]\n",
        "        probability += trigram_model.get((prev_prev_word,prev_word, word), 0.0)\n",
        "    return probability\n",
        "\n",
        "def beam_search_decode(initial_state, max_depth, beam_width, generate_candidates_fn, score_fn):\n",
        "    candidates = [(initial_state, 1.0)]\n",
        "\n",
        "    for depth in range(max_depth):\n",
        "        new_candidates = []\n",
        "        for candidate, prob in candidates:\n",
        "            for next_state in generate_candidates_fn(candidate):\n",
        "                new_prob = prob + score_fn(next_state)\n",
        "                new_candidates.append((next_state, new_prob))\n",
        "\n",
        "\n",
        "\n",
        "        new_candidates = sorted(new_candidates, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        candidates = new_candidates[:beam_width]\n",
        "\n",
        "    best_sequence, best_prob = max(candidates, key=lambda x: x[1])\n",
        "    return best_sequence\n",
        "\n",
        "\n",
        "test_sentence = \"I would like to\"\n",
        "initial_state = test_sentence.split(' ')[-2:]\n",
        "max_depth = 20\n",
        "beam_width = 3\n",
        "best_sequence = beam_search_decode(initial_state, max_depth, beam_width, generate_candidates, score)\n",
        "print(test_sentence)\n",
        "print(' '.join(best_sequence[2:]))  # Excluding the 2 first <start>\" tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USypWhrrbOJX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIFkLCn3412c"
      },
      "source": [
        "# Spelling corrector"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UHxRduLz1rT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate proba\n",
        "def calculate_bigram_probability(ngram_counter, ngram_minus_one_counter, ngram, alpha, vocab_size):\n",
        "    \"\"\"\n",
        "    Calculate bigram probability with Laplace smoothing\n",
        "    :param bigram_counter: Counter which the key is a tuple of ngram and value its frequency\n",
        "    :param gram_counter: Counter which the key is a tuple of n-1gram and value its frequency\n",
        "    :param ngram: tuple\n",
        "    :param alpha: float hyperparameter for Laplace smoothing\n",
        "    :param vocab_size: int value which defines the whole size of the corpus\n",
        "    :return: float probability of the ngram inside the corpus\n",
        "    \"\"\"\n",
        "    ngram_count = ngram_counter[ngram]\n",
        "    ngram_minus_one_count = ngram_minus_one_counter[(ngram[0:2],)]\n",
        "    ngram_prob = (ngram_count + alpha) / (ngram_minus_one_count + (alpha * vocab_size))\n",
        "    ngram_prob = math.log2(ngram_prob)\n",
        "    # if ngram_prob>0.6:\n",
        "    #     print(f'ngram: {ngram}, ngram_count: {ngram_count}, ngram_minus_one_count: {ngram_minus_one_count}')\n",
        "    return ngram_prob"
      ],
      "metadata": {
        "id": "blhBwsFO1_eq"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbY0l67M43OK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "healIGWE0-ZP",
        "outputId": "f8f18791-73fd-4a07-a5a6-1fb0df0433fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Damerau–Levenshtein distance between 'kitten' and 'sitting': 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use damerau_levenshtein_distance, which is better for spelling correction because it contains also transposition"
      ],
      "metadata": {
        "id": "t5hnS4-0eBvq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "eXKSs606-LOZ"
      },
      "outputs": [],
      "source": [
        "# Leveinstein Destance with transposition.\n",
        "def damerau_levenshtein_distance(s1, s2):\n",
        "    \"\"\"\n",
        "    Calculate the Damerau–Levenshtein distance between two strings.\n",
        "    \"\"\"\n",
        "    len_s1 = len(s1)\n",
        "    len_s2 = len(s2)\n",
        "    d = [[0] * (len_s2 + 1) for _ in range(len_s1 + 1)]\n",
        "\n",
        "    for i in range(len_s1 + 1):\n",
        "        d[i][0] = i\n",
        "    for j in range(len_s2 + 1):\n",
        "        d[0][j] = j\n",
        "\n",
        "    for i in range(1, len_s1 + 1):\n",
        "        for j in range(1, len_s2 + 1):\n",
        "            cost = 0 if s1[i - 1] == s2[j - 1] else 1\n",
        "            d[i][j] = min(\n",
        "                d[i - 1][j] + 1,  # deletion\n",
        "                d[i][j - 1] + 1,  # insertion\n",
        "                d[i - 1][j - 1] + cost,  # substitution\n",
        "            )\n",
        "            if i > 1 and j > 1 and s1[i - 1] == s2[j - 2] and s1[i - 2] == s2[j - 1]:\n",
        "                d[i][j] = min(d[i][j], d[i - 2][j - 2] + cost)  # transposition\n",
        "\n",
        "    return d[len_s1][len_s2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2h1_XXt-sRf",
        "outputId": "4617559c-feb9-423d-8399-453e4d2bac55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Candidate words for 'Japn': ['Japan', 'Jan', 'an', 'main', 'can']\n"
          ]
        }
      ],
      "source": [
        "# Take a word and the vocab and produce candidates/\n",
        "def generate_candidate_word(word, word_list, max_candidates=5):\n",
        "    \"\"\"\n",
        "    Generate candidate words for a misspelled word.\n",
        "\n",
        "    Parameters:\n",
        "    - word: The misspelled word.\n",
        "    - word_list: List of words to search for candidates.\n",
        "    - max_candidates: Maximum number of candidates\n",
        "\n",
        "    Returns:\n",
        "    - A list of candidate words.\n",
        "    \"\"\"\n",
        "    candidates = []\n",
        "    for candidate in word_list:\n",
        "        distance = damerau_levenshtein_distance(word, candidate)\n",
        "\n",
        "        candidates.append((candidate, distance))\n",
        "\n",
        "    # Sort candidates by Levenshtein distance in ascending order\n",
        "    candidates.sort(key=lambda x: x[1])\n",
        "    candidates = candidates[:max_candidates]\n",
        "\n",
        "    # Return only the candidate words (not the distances)\n",
        "    return [candidate[0] for candidate in candidates]\n",
        "\n",
        "# Example usage\n",
        "misspelled_word = \"Japn\"\n",
        "\n",
        "candidates = generate_candidate_word(misspelled_word, vocab, 5)\n",
        "print(f\"Candidate words for '{misspelled_word}': {candidates}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9_LgZLvUeT7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEucc999KyY3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHMNNEdXKyas"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u4O4NNPKyeE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBZHnS8UbUSC"
      },
      "source": [
        "NEW NOISY CHANNEL SPELLING CORRECTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTrts3HYb65F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "PIBH-XtYb68a"
      },
      "outputs": [],
      "source": [
        "# Generate candidates\n",
        "def generate_candidate_Distance(state,word,vocab):\n",
        "    # Given state , generate possible next words\n",
        "    second_word = state[-2]\n",
        "    last_word = state[-1]\n",
        "    current = word\n",
        "    # print(current)\n",
        "    cands = generate_candidate_word(current,vocab,5)\n",
        "    # Find candidates words\n",
        "    next_words = [word for word in vocab if ((word in cands))]\n",
        "\n",
        "    # next_words = [word for (prev_prev_word, prev_word, word) in trigram_model if (prev_word == last_word and prev_prev_word==second_word and (word in cands))]\n",
        "    # print(next_words)\n",
        "    return [state + [next_word] for next_word in next_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Edt86lFdK6u_",
        "outputId": "abc1c5b9-42aa-45e5-92c8-8abd3236c736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 -26.72196843194794 -1.0\n",
            ",\n",
            "0 -26.72196843194794 -1.0\n",
            "a\n",
            "0 -18.074510005493018 -1.0\n",
            ".\n",
            "0 -19.07091674076901 -1.0\n",
            "DI\n",
            "0 -14.990225141240096 0.0\n",
            "I\n",
            "[(['<s>', '<s>', 'I'], -14.990225141240096), (['<s>', '<s>', '.'], -19.074510005493018), (['<s>', '<s>', 'DI'], -20.07091674076901), (['<s>', '<s>', ','], -27.72196843194794), (['<s>', '<s>', 'a'], -27.72196843194794)]\n",
            "-14.990225141240096 -28.351209357214067 -1.0\n",
            "a\n",
            "-14.990225141240096 -28.351209357214067 -1.0\n",
            "an\n",
            "-14.990225141240096 -28.351209357214067 -1.0\n",
            "as\n",
            "-14.990225141240096 -28.351209357214067 -1.0\n",
            "at\n",
            "-14.990225141240096 -28.351209357214067 0.0\n",
            "am\n",
            "-19.074510005493018 -31.43549422146699 -1.0\n",
            "a\n",
            "-19.074510005493018 -31.43549422146699 -1.0\n",
            "an\n",
            "-19.074510005493018 -31.43549422146699 -1.0\n",
            "as\n",
            "-19.074510005493018 -31.43549422146699 -1.0\n",
            "at\n",
            "-19.074510005493018 -31.43549422146699 0.0\n",
            "am\n",
            "-20.07091674076901 -32.43190095674298 -1.0\n",
            "a\n",
            "-20.07091674076901 -32.43190095674298 -1.0\n",
            "an\n",
            "-20.07091674076901 -32.43190095674298 -1.0\n",
            "as\n",
            "-20.07091674076901 -32.43190095674298 -1.0\n",
            "at\n",
            "-20.07091674076901 -32.43190095674298 0.0\n",
            "am\n",
            "-27.72196843194794 -40.08295264792191 -1.0\n",
            "a\n",
            "-27.72196843194794 -40.08295264792191 -1.0\n",
            "an\n",
            "-27.72196843194794 -40.08295264792191 -1.0\n",
            "as\n",
            "-27.72196843194794 -40.08295264792191 -1.0\n",
            "at\n",
            "-27.72196843194794 -40.08295264792191 0.0\n",
            "am\n",
            "-27.72196843194794 -40.08295264792191 -1.0\n",
            "a\n",
            "-27.72196843194794 -40.08295264792191 -1.0\n",
            "an\n",
            "-27.72196843194794 -40.08295264792191 -1.0\n",
            "as\n",
            "-27.72196843194794 -40.08295264792191 -1.0\n",
            "at\n",
            "-27.72196843194794 -40.08295264792191 0.0\n",
            "am\n",
            "[(['<s>', '<s>', 'I', 'am'], -43.34143449845416), (['<s>', '<s>', 'I', 'a'], -44.34143449845416), (['<s>', '<s>', 'I', 'an'], -44.34143449845416), (['<s>', '<s>', 'I', 'as'], -44.34143449845416), (['<s>', '<s>', 'I', 'at'], -44.34143449845416)]\n",
            "-43.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "closing\n",
            "-43.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "voting\n",
            "-43.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "upcoming\n",
            "-43.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "going\n",
            "-43.34143449845416 -41.71219357318804 0.0\n",
            "coming\n",
            "-44.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "closing\n",
            "-44.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "voting\n",
            "-44.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "upcoming\n",
            "-44.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "going\n",
            "-44.34143449845416 -41.71219357318804 0.0\n",
            "coming\n",
            "-44.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "closing\n",
            "-44.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "voting\n",
            "-44.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "upcoming\n",
            "-44.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "going\n",
            "-44.34143449845416 -41.71219357318804 0.0\n",
            "coming\n",
            "-44.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "closing\n",
            "-44.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "voting\n",
            "-44.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "upcoming\n",
            "-44.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "going\n",
            "-44.34143449845416 -41.71219357318804 0.0\n",
            "coming\n",
            "-44.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "closing\n",
            "-44.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "voting\n",
            "-44.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "upcoming\n",
            "-44.34143449845416 -41.71219357318804 -1.5849625007211563\n",
            "going\n",
            "-44.34143449845416 -41.71219357318804 0.0\n",
            "coming\n",
            "[(['<s>', '<s>', 'I', 'am', 'coming'], -85.05362807164221), (['<s>', '<s>', 'I', 'a', 'coming'], -86.05362807164221), (['<s>', '<s>', 'I', 'an', 'coming'], -86.05362807164221), (['<s>', '<s>', 'I', 'as', 'coming'], -86.05362807164221), (['<s>', '<s>', 'I', 'at', 'coming'], -86.05362807164221)]\n",
            "-85.05362807164221 -55.07317778916201 0.0\n",
            "to\n",
            "-85.05362807164221 -55.07317778916201 -1.0\n",
            "Co\n",
            "-85.05362807164221 -55.07317778916201 -1.0\n",
            "no\n",
            "-85.05362807164221 -55.07317778916201 -1.0\n",
            "do\n",
            "-85.05362807164221 -55.07317778916201 -1.0\n",
            "two\n",
            "-86.05362807164221 -55.07317778916201 0.0\n",
            "to\n",
            "-86.05362807164221 -55.07317778916201 -1.0\n",
            "Co\n",
            "-86.05362807164221 -55.07317778916201 -1.0\n",
            "no\n",
            "-86.05362807164221 -55.07317778916201 -1.0\n",
            "do\n",
            "-86.05362807164221 -55.07317778916201 -1.0\n",
            "two\n",
            "-86.05362807164221 -55.07317778916201 0.0\n",
            "to\n",
            "-86.05362807164221 -55.07317778916201 -1.0\n",
            "Co\n",
            "-86.05362807164221 -55.07317778916201 -1.0\n",
            "no\n",
            "-86.05362807164221 -55.07317778916201 -1.0\n",
            "do\n",
            "-86.05362807164221 -55.07317778916201 -1.0\n",
            "two\n",
            "-86.05362807164221 -55.07317778916201 0.0\n",
            "to\n",
            "-86.05362807164221 -55.07317778916201 -1.0\n",
            "Co\n",
            "-86.05362807164221 -55.07317778916201 -1.0\n",
            "no\n",
            "-86.05362807164221 -55.07317778916201 -1.0\n",
            "do\n",
            "-86.05362807164221 -55.07317778916201 -1.0\n",
            "two\n",
            "-86.05362807164221 -55.07317778916201 0.0\n",
            "to\n",
            "-86.05362807164221 -55.07317778916201 -1.0\n",
            "Co\n",
            "-86.05362807164221 -55.07317778916201 -1.0\n",
            "no\n",
            "-86.05362807164221 -55.07317778916201 -1.0\n",
            "do\n",
            "-86.05362807164221 -55.07317778916201 -1.0\n",
            "two\n",
            "[(['<s>', '<s>', 'I', 'am', 'coming', 'to'], -140.1268058608042), (['<s>', '<s>', 'I', 'am', 'coming', 'Co'], -141.1268058608042), (['<s>', '<s>', 'I', 'am', 'coming', 'no'], -141.1268058608042), (['<s>', '<s>', 'I', 'am', 'coming', 'do'], -141.1268058608042), (['<s>', '<s>', 'I', 'am', 'coming', 'two'], -141.1268058608042)]\n",
            "-140.1268058608042 -68.43416200513597 -1.5849625007211563\n",
            "to\n",
            "-140.1268058608042 -68.43416200513597 -1.0\n",
            "down\n",
            "-140.1268058608042 -68.43416200513597 -1.0\n",
            "own\n",
            "-140.1268058608042 -68.43416200513597 -1.0\n",
            "ton\n",
            "-140.1268058608042 -68.43416200513597 -1.0\n",
            "sown\n",
            "-141.1268058608042 -68.43416200513597 -1.5849625007211563\n",
            "to\n",
            "-141.1268058608042 -68.43416200513597 -1.0\n",
            "down\n",
            "-141.1268058608042 -68.43416200513597 -1.0\n",
            "own\n",
            "-141.1268058608042 -68.43416200513597 -1.0\n",
            "ton\n",
            "-141.1268058608042 -68.43416200513597 -1.0\n",
            "sown\n",
            "-141.1268058608042 -68.43416200513597 -1.5849625007211563\n",
            "to\n",
            "-141.1268058608042 -68.43416200513597 -1.0\n",
            "down\n",
            "-141.1268058608042 -68.43416200513597 -1.0\n",
            "own\n",
            "-141.1268058608042 -68.43416200513597 -1.0\n",
            "ton\n",
            "-141.1268058608042 -68.43416200513597 -1.0\n",
            "sown\n",
            "-141.1268058608042 -68.43416200513597 -1.5849625007211563\n",
            "to\n",
            "-141.1268058608042 -68.43416200513597 -1.0\n",
            "down\n",
            "-141.1268058608042 -68.43416200513597 -1.0\n",
            "own\n",
            "-141.1268058608042 -68.43416200513597 -1.0\n",
            "ton\n",
            "-141.1268058608042 -68.43416200513597 -1.0\n",
            "sown\n",
            "-141.1268058608042 -68.43416200513597 -1.5849625007211563\n",
            "to\n",
            "-141.1268058608042 -68.43416200513597 -1.0\n",
            "down\n",
            "-141.1268058608042 -68.43416200513597 -1.0\n",
            "own\n",
            "-141.1268058608042 -68.43416200513597 -1.0\n",
            "ton\n",
            "-141.1268058608042 -68.43416200513597 -1.0\n",
            "sown\n",
            "[(['<s>', '<s>', 'I', 'am', 'coming', 'to', 'down'], -209.5609678659402), (['<s>', '<s>', 'I', 'am', 'coming', 'to', 'own'], -209.5609678659402), (['<s>', '<s>', 'I', 'am', 'coming', 'to', 'ton'], -209.5609678659402), (['<s>', '<s>', 'I', 'am', 'coming', 'to', 'sown'], -209.5609678659402), (['<s>', '<s>', 'I', 'am', 'coming', 'to', 'to'], -210.14593036666136)]\n",
            "I am coming to down\n"
          ]
        }
      ],
      "source": [
        "def score(state):\n",
        "    # Calculate the probability of the word sequence using the bigram model\n",
        "    probability = 0\n",
        "    for i in range(1, len(state)):\n",
        "        prev_prev_word, prev_word, word = state[i-2], state[i-1], state[i]\n",
        "        probability += calculate_bigram_probability(trigram_counter,bigram_counter,(prev_prev_word,prev_word, word),0.01,len(vocab))\n",
        "        # probability += trigram_model.get((prev_prev_word,prev_word, word), 0.0) + 0.1*bigram_model.get((prev_word,word),0.0)\n",
        "    return probability\n",
        "\n",
        "\n",
        "def beam_search_decode(sentence, max_depth, beam_width, generate_candidates_fn, score_fn):\n",
        "    initial_state = ['<s>','<s>']\n",
        "    candidates = [(initial_state, 0)]\n",
        "    sentence = sentence\n",
        "    for depth in range(max_depth):\n",
        "        new_candidates = []\n",
        "        for candidate, prob in candidates:\n",
        "            for next_state in generate_candidates_fn(candidate,sentence[depth],vocab):\n",
        "                print(prob,score_fn(next_state),math.log2(1 / (damerau_levenshtein_distance(next_state[-1],sentence[depth]) + 1)) )\n",
        "                print(next_state[-1])\n",
        "                # prob we add the previous prob, the prob of the next state and the inverse of the distance\n",
        "                new_prob = prob + score_fn(next_state) + math.log2(1 / (damerau_levenshtein_distance(next_state[-1],sentence[depth]) + 1))\n",
        "\n",
        "                new_candidates.append((next_state, new_prob))\n",
        "\n",
        "\n",
        "\n",
        "        new_candidates = sorted(new_candidates, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        candidates = new_candidates[:beam_width]\n",
        "        print(candidates)\n",
        "    best_sequence, best_prob = max(candidates, key=lambda x: x[1])\n",
        "    return best_sequence\n",
        "\n",
        "\n",
        "test_sentence = \"I am coming to town\"\n",
        "max_depth = len(word_tokenize(test_sentence))\n",
        "beam_width = 5\n",
        "best_sequence = beam_search_decode(word_tokenize(test_sentence), max_depth, beam_width, generate_candidate_Distance, score)\n",
        "print(' '.join(best_sequence[2:]))  # Excluding the \"<start>\" token"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We dont have town, so our model correctly changes it to town"
      ],
      "metadata": {
        "id": "QIv66QpEe1Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "NTK9jUMScMC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081b27e1-406f-4cbe-cf34-9c19c5609117"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "unigram_counter[('town'),0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3slcPuRX4_UK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-guBLnYb5JDJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}